# Statement of Work

Multi-modal Brain Visualization
Team Red Lemur, 2017

| Sprint   | Date Due | Requirements: Portion of manuscript (and package) corresponding to... |
|---|---|---|
| Sprint 0: Scope & Plan | 9/26 | <ul><li>Background reading</li>  <li>Proposal slides</li>  <li>Statement of work</li> <li>Bibliography</li></ul> |
| Sprint 1: Top 10s | 11/1 | <ul><li>Scope problems from literature that this tool can solve</li><li>Graphing library to produce top n > 10 plots for each modality (some are one-to-one, some are many-to-one aggregate)</li><li>Notebook to produce all plots for a single subject, and aggregate plots for entire HBNB</li><li>choose a plotting library and design a uniform aesthetic for all plots</li></ul>  |
| Sprint 2: Refine and Deploy Top 10s | 12/15  | <ul><li>Generate and then refine top plots to get n=10 for each modality (some one-to-one, some many-to-one)</li><li>Create a MVP web service (Dockerized and running on EC2) where a user can<ul><li>Upload a .csv file of Phenotypic data, and can later browse through all phenotypic visualizations created</li><li>Specify a S3 bucket containing properly formatted EEG / fMRI data, and can later browse through all EEG / fMRI visualizations created</li></ul>  |
| Sprint 3: Cross-modal visualizations | 2/15   | <ul><li>Visualizations derived from >1 modality</li><li>Test dependence/independence of signals from different modalities</li><li>Basic demonstrations of 'looking at' biomarkers cited in current research</li></ul> |
| Sprint 4: Wrap up webservice & analysis | 4/1 | <ul><li>Add Sprint 3 work into webservice deployment, make 'production ready'</li><li>get as many datasets as possible to work with tool</li><li>Generalize plotting if useful for other teams in the class (may be done by making an AVATR plug-in, or our own generalized services)</li></ul> |

### Sprint 2 DoDs
- A Flask web app wrapped in a Docker container, deployed on an Amazon EC2 instance. A user can navigate to this web app through a web browser and:
  - upload a .csv file of phenotypic data (in a format that we specify, the same format which the HBN Phenotypic dataset is currently in). The web app will then automatically generate all plots which can be created by Lemur related to the phenotypic paradigm. Once the web service is done generating all of these plots, it will create a browsable static web page for the dataset which the user can navigate to and view all of the generated plots. Alternatively, a user can download the static web page as a .zip file, and view that way.
  - upload a .csv descriptor of a EEG or fMRI living in a public S3 bucket following the BIDS format (or the current stable version of the BIDS EEG Extension). The web app will then automatically generate all plots which can be generated by Lemur related to the EEG or fMRI paradigm. Once the web service is done generating all of these plots, it will create a browsable static web page for the dataset which the user can navigate to and view all of the generated plots. Alternatively, a user can download the static web page as a .zip file, and view that way
  
*Good start/plan.  I want to see a wireframe next week showing what the user experience will look like.  I suspect that there will be 10 "tabs" on a single html page, so that users can simply select which image to look at.  this is because each image might be several MB, and i suspect the user experience will be better with multiple tabs. Are the static webpages that are generated permanent? Where are they stored? S3? How can somebody "share" them with somebody else, send a link? So, no authentication? Please clarify details of the user experience.*
  
  
- A plotting library which can generate one to one or aggregate plots for each of the EEG, fMRI, Phenotypic modalities. This library will include 10 possible plots for each modality, where 7 are aggregate plots and 3 are one-to-one plots. This library will be available via PyPI and have a documentation page generated via Sphinx. The documentation page will have information on how to use each plotting function, as well as general information for the input format of each data modality. The plots to include will be geared towards answering questions relating to the p-factor, or visualizations to create a dimensional view of mental disorders.

*This week, I want to see an example of **every single plot you will be providing**.  I want them to include all 10 meda plots for aggregate plots.* 

*I maintain that 10 plots for **graphs** will be incredibly useful.  For example, for both the EEG & fMRI data, they are often represented as graphs.  So, if you have 10 graph plots, that works for both, you'd just need a few modality specific plots.  Check out https://github.com/neurodata/Graph-Explorer and https://github.com/neurodata/ExploratoryGraph for some examples.*

*Another task is to get the HBN dataset "tidy", meaning to get the data into a format that meda can run on and that the results are sensible.  This may require interating to address mislabeled columns, missing numbers, etc.   The DoD is a csv file that is meda compliant. *

*For your webservice to work sensibly on the phenotypic data, simply ingesting a csv file will be inadequate in the long term.  For example, some variables will be categorical will >2 categories.  MEDA will need to know that so when you do factor analysis, it operates on those data appropriately.  So, there should also be a json file and spec that defines things like the type for each column, and maybe other stuff. I've uploaded a file to your slack channel.  That file should not be made public. Determine whether you want this to happen in sprint 1 or not and specify.*



