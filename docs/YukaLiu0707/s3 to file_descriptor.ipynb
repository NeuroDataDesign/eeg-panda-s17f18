{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lemur.datasets as lds\n",
    "import lemur.metrics as lms\n",
    "import lemur.plotters as lpl\n",
    "import lemur.embedders as leb\n",
    "import boto3\n",
    "import io\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current method (EEG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BIDSParser:\n",
    "    def __init__(self, base_path):\n",
    "        dataset_name = os.path.basename(os.path.normpath(base_path))\n",
    "        dataset = {}\n",
    "        subjects = [os.path.basename(x) for x in glob.glob(base_path + \"/*\")]\n",
    "        if \"chanlocs.csv\" in subjects:\n",
    "            subjects.remove(\"chanlocs.csv\")\n",
    "        if \"metadata.json\" in subjects:\n",
    "            subjects.remove(\"metadata.json\")\n",
    "#         print('base_path')\n",
    "#         print (base_path)\n",
    "#         print('subjects')\n",
    "#         print (subjects)\n",
    "        for s in subjects:\n",
    "            dataset.update({s:{}})\n",
    "        for s in subjects:\n",
    "            modalities = [os.path.basename(x) for x in glob.glob(os.path.join(base_path, s) + \"/*\")]\n",
    "#             print('modalities')\n",
    "#             print(modalities)\n",
    "            for m in modalities:\n",
    "                dataset[s].update({m:{}})\n",
    "                files = [os.path.basename(x) for x in glob.glob(os.path.join(base_path, s, m) + \"/*\")]\n",
    "#                 print(files)\n",
    "                for f in files:\n",
    "                    t = \"\".join(f.split(\"_\")[1:]).split(\".\")[0]\n",
    "                    dataset[s][m].update({t:f})\n",
    "        self.dataset = dataset\n",
    "        self.base_path = base_path\n",
    "#         print(self.dataset)\n",
    "\n",
    "    def getModalityFrame(self, modality, extension):\n",
    "        files = []\n",
    "        subjects = []\n",
    "        tasks = []\n",
    "        for s in self.dataset.keys():\n",
    "            for t in self.dataset[s][modality].keys():\n",
    "                f = self.dataset[s][modality][t]\n",
    "                if f.endswith(extension):\n",
    "                    files.append(os.path.join(self.base_path, s, modality, f))\n",
    "                    subjects.append(s)\n",
    "                    tasks.append(t)\n",
    "#         print (files)\n",
    "#         print (subjects)\n",
    "#         print (tasks)\n",
    "        d = {\n",
    "            \"resource_path\": files,\n",
    "            \"subjects\": subjects,\n",
    "            \"tasks\": tasks        \n",
    "        }\n",
    "        return pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       resource_path          subjects  \\\n",
      "0  /Users/YujiaLiu/Desktop/download_test/data/eeg...  sub-NDARAC904DMU   \n",
      "1  /Users/YujiaLiu/Desktop/download_test/data/eeg...  sub-NDARAA117NEJ   \n",
      "\n",
      "                  tasks  \n",
      "0  task-RestingStateeeg  \n",
      "1  task-RestingStateeeg  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "BASE = \"/Users/YujiaLiu/Desktop/download_test/data\"\n",
    "DATASET = \"eeg\"\n",
    "root = os.path.join(BASE, DATASET)\n",
    "# root = '/eeg'\n",
    "# print (root)\n",
    "bp = BIDSParser(root)\n",
    "dataset_descriptor = bp.getModalityFrame(\"preprocessed\", \".pkl\").iloc[:6]\n",
    "out_base = os.path.join(BASE, \"eeg_derivatives\")\n",
    "out_emb_base = os.path.join(BASE, \"eeg_embedded_deriatives\")\n",
    "os.makedirs(out_base + \"/agg\", exist_ok=True)\n",
    "os.makedirs(out_emb_base + \"/agg\", exist_ok=True)\n",
    "print (dataset_descriptor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chanlocs = pd.read_csv(root+\"/chanlocs.csv\")\n",
    "spatial = lds.DataSet(chanlocs[[\"X\", \"Y\", \"Z\"]], \"Spatial\")\n",
    "spatialDM = lds.DistanceMatrix(spatial, lms.VectorDifferenceNorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "eds = lds.EEGDataSet(dataset_descriptor)\n",
    "# Create a lemur distance matrix based on the EEG data\n",
    "DM = lds.DistanceMatrix(eds, lms.FroCorr)\n",
    "DM.name = \"eeg-DistanceMatrix\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an embedded distance matrix object under MDS\n",
    "MDSEmbedder = leb.MDSEmbedder(num_components=10)\n",
    "EEG_Embedded = MDSEmbedder.embed(DM)\n",
    "for i in range(eds.n):\n",
    "    single_ds = eds.getResourceDS(i)\n",
    "    lpl.SparkLinePlotter(single_ds, mode=\"savediv\", base_path=out_base).plot(sample_freq=500)\n",
    "\n",
    "for i in range(eds.n):\n",
    "    single_ds = eds.getResourceDS(i)\n",
    "    single_DM = lds.DataSet(single_ds.D.corr(), single_ds.name)\n",
    "    lpl.SpatialConnectivity(single_DM, mode=\"savediv\",\n",
    "                            base_path=out_base).plot(spatial)\n",
    "for i in range(eds.n):\n",
    "    single_ds = eds.getResourceDS(i)\n",
    "    single_DM = lds.DataSet(single_ds.D.corr(), single_ds.name)\n",
    "    lpl.ConnectedScatterplot(single_DM,\n",
    "                             mode=\"savediv\",\n",
    "                             base_path=out_base).plot(spatialDM)\n",
    "\n",
    "lpl.SquareHeatmap(DM, mode=\"savediv\", base_path=out_base).plot()\n",
    "lpl.Heatmap(EEG_Embedded, mode=\"savediv\", base_path=out_emb_base).plot()\n",
    "\n",
    "lpl.EigenvectorHeatmap(DM, mode=\"savediv\", base_path=out_base).plot()\n",
    "lpl.EigenvectorHeatmap(EEG_Embedded, mode=\"savediv\",\n",
    "                       base_path=out_emb_base).plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read files directly from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "BASE = '/Users/YujiaLiu/Desktop/test'\n",
    "DATASET = 'eeg'\n",
    "root = os.path.join(BASE, DATASET)\n",
    "out_base = os.path.join(BASE, \"eeg_derivatives\")\n",
    "out_emb_base = os.path.join(BASE, \"eeg_embedded_deriatives\")\n",
    "os.makedirs(out_base + \"/agg\", exist_ok=True)\n",
    "os.makedirs(out_emb_base + \"/agg\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = []\n",
    "s = ['sub-NDARAC904DMU', 'sub-NDARAA117NEJ']\n",
    "t = ['task-RestingStateeeg', 'task-RestingStateeeg']\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket('redlemurtest')\n",
    "# Directly read through S3 bucket and pass into pandas dataframe\n",
    "for obj in bucket.objects.all():\n",
    "    key = obj.key\n",
    "    if key.endswith('.pkl'):\n",
    "        body = obj.get()['Body'].read()\n",
    "        pkl = pd.read_pickle(io.BytesIO(body))\n",
    "        f.append(pkl)\n",
    "    if key.endswith('chanlocs.csv'):\n",
    "        body = obj.get()['Body'].read()\n",
    "        chanlocs = pd.read_csv(io.BytesIO(body))\n",
    "spatial = lds.DataSet(chanlocs[[\"X\", \"Y\", \"Z\"]], \"Spatial\")\n",
    "spatialDM = lds.DistanceMatrix(spatial, lms.VectorDifferenceNorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       resource_path          subjects  \\\n",
      "0  [[0.0, 2.4754, 52.105, 37.534, 52.535, 76.26, ...  sub-NDARAC904DMU   \n",
      "1  [[0.0, 261.64, 375.68, 345.7, 97.827, 381.74, ...  sub-NDARAA117NEJ   \n",
      "\n",
      "                  tasks  \n",
      "0  task-RestingStateeeg  \n",
      "1  task-RestingStateeeg  \n"
     ]
    }
   ],
   "source": [
    "d = {\n",
    "            \"resource_path\": f,\n",
    "            \"subjects\": s,\n",
    "            \"tasks\": t        \n",
    "    }\n",
    "descriptor = pd.DataFrame(d)\n",
    "print (descriptor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Since we read in the pickle directly, we need to modify several functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceMatrix:\n",
    "    \"\"\"A distance matrix computed from a DataSet object.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : :obj:`DiskDataSet`\n",
    "        A dataset on which to compute the distance matrix\n",
    "    metric : function\n",
    "        A distance used to compute the distance matrix.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    dataset : :obj:`DiskDataSet`\n",
    "        A dataset on which to compute the distance matrix\n",
    "    metric : function\n",
    "        A distance used to compute the distance matrix.\n",
    "    N : int\n",
    "        Number of data points in the dataset.\n",
    "    matrix : :obj:`ndarray`\n",
    "        The distance matrix.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, metric):\n",
    "        self.DS = dataset\n",
    "        self.name = self.DS.name\n",
    "        self.labels = self.DS.D.index.values\n",
    "        self.label_name = self.DS.D.index.name\n",
    "        self.metric = metric\n",
    "        self.metric_name = metric.__name__\n",
    "        self.n = self.DS.n\n",
    "        parameterization = parameterize(self.DS)\n",
    "        self.D = np.zeros([self.n, self.n])\n",
    "        for i in range(self.n):\n",
    "            I = parameterization[i]\n",
    "            for j in range(i + 1):\n",
    "                J = parameterization[j]\n",
    "                self.D[i, j] = self.metric.compare(I, J)\n",
    "                self.D[j, i] = self.D[i, j]\n",
    "        self.D = pd.DataFrame(self.D)\n",
    "        self.D.index = self.DS.D.index\n",
    "        self.D.index.name = self.DS.D.index.name\n",
    "\n",
    "    def getMatrix(self):\n",
    "        \"\"\"Get the distance matrix.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        :obj:`ndarray`\n",
    "            The distance matrix.\n",
    "\n",
    "        \"\"\"\n",
    "        return self.D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameterize(D):\n",
    "        \"\"\"Compute the correlation matrix of a single data point.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        D : :obj:`DataSet`\n",
    "            The lemur data set object to parameterize.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        :obj:`list` of :obj:`ndarray`\n",
    "            The correlation matrix of each object in the dataset.\n",
    "\n",
    "        \"\"\"\n",
    "        with np.errstate(divide = 'ignore', invalid = 'ignore'):\n",
    "            return list(map(lambda j: np.nan_to_num(np.corrcoef(D.getMatrix(j))), range(D.n)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet:\n",
    "    def __init__(self, D, name=\"default\"):\n",
    "        self.D = D\n",
    "        self.n, self.d = self.D.shape\n",
    "        self.name = name\n",
    "\n",
    "    def getResource(self, index):\n",
    "        return self.D.iloc[index, :]\n",
    "\n",
    "    def saveMetaData(self, filepath):\n",
    "        metadata = dict(d=self.d, n=self.n, name=self.name)\n",
    "        string = json.dumps(metadata, indent=2)\n",
    "        with open(filepath, 'w') as f:\n",
    "            f.write(string)\n",
    "        return string\n",
    "\n",
    "    def getMatrix(self):\n",
    "        return self.D.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataSet:\n",
    "\n",
    "    def __init__(self, dataframe_descriptor, name=\"fmri\"):\n",
    "        self.D = dataframe_descriptor\n",
    "        self.D.index = self.D[\"subjects\"].astype(str) + \"-\" + self.D[\"tasks\"].astype(str)\n",
    "        self.D.index.name = \"index\"\n",
    "        self.name = name\n",
    "        self.n = self.D.shape[0]\n",
    "\n",
    "    def getResource(self, index):\n",
    "        resource = self.D.ix[index]\n",
    "        return resource\n",
    "\n",
    "    def getMatrix(self, index):\n",
    "        resource_path = self.D.ix[index][0]\n",
    "        return resource_path.T\n",
    "#         with open(resource_path, \"rb\") as f:\n",
    "#             return pkl.load(f).T\n",
    "\n",
    "    def getResourceDS(self, index):\n",
    "        resource = self.getResource(index)\n",
    "        matrix = self.getMatrix(index)\n",
    "        D = pd.DataFrame(matrix.T)\n",
    "        name = \"%s/%s\"%(resource[1], resource[2])\n",
    "        DS = DataSet(D, name)\n",
    "        return DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:15: DeprecationWarning:\n",
      "\n",
      "\n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use modified functions to read in new dataframe\n",
    "import numpy as np\n",
    "eds = EEGDataSet(descriptor)\n",
    "# Create a lemur distance matrix based on the EEG data\n",
    "DM = DistanceMatrix(eds, lms.FroCorr)\n",
    "DM.name = \"eeg-DistanceMatrix\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an embedded distance matrix object under MDS\n",
    "MDSEmbedder = leb.MDSEmbedder(num_components=10)\n",
    "EEG_Embedded = MDSEmbedder.embed(DM)\n",
    "for i in range(eds.n):\n",
    "    single_ds = eds.getResourceDS(i)\n",
    "    lpl.SparkLinePlotter(single_ds, mode=\"savediv\", base_path=out_base).plot(sample_freq=500)\n",
    "for i in range(eds.n):\n",
    "    single_ds = eds.getResourceDS(i)\n",
    "    single_DM = lds.DataSet(single_ds.D.corr(), single_ds.name)\n",
    "    lpl.SpatialConnectivity(single_DM, mode=\"savediv\",\n",
    "                            base_path=out_base).plot(spatial)\n",
    "for i in range(eds.n):\n",
    "    single_ds = eds.getResourceDS(i)\n",
    "    single_DM = lds.DataSet(single_ds.D.corr(), single_ds.name)\n",
    "    lpl.ConnectedScatterplot(single_DM,\n",
    "                             mode=\"savediv\",\n",
    "                             base_path=out_base).plot(spatialDM)\n",
    "\n",
    "lpl.SquareHeatmap(DM, mode=\"savediv\", base_path=out_base).plot()\n",
    "lpl.Heatmap(EEG_Embedded, mode=\"savediv\", base_path=out_emb_base).plot()\n",
    "\n",
    "lpl.EigenvectorHeatmap(DM, mode=\"savediv\", base_path=out_base).plot()\n",
    "lpl.EigenvectorHeatmap(EEG_Embedded, mode=\"savediv\",\n",
    "                       base_path=out_emb_base).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/YujiaLiu/Desktop/test/eeg_derivatives/agg/squareheat.html\n",
      "/Users/YujiaLiu/Desktop/test/eeg_derivatives/agg/evheat.html\n",
      "/Users/YujiaLiu/Desktop/test/eeg_derivatives/sub-NDARAC904DMU/task-RestingStateeeg/spatialconn.html\n",
      "/Users/YujiaLiu/Desktop/test/eeg_derivatives/sub-NDARAC904DMU/task-RestingStateeeg/connectedscatter.html\n",
      "/Users/YujiaLiu/Desktop/test/eeg_derivatives/sub-NDARAC904DMU/task-RestingStateeeg/sparkline.html\n",
      "/Users/YujiaLiu/Desktop/test/eeg_derivatives/sub-NDARAA117NEJ/task-RestingStateeeg/spatialconn.html\n",
      "/Users/YujiaLiu/Desktop/test/eeg_derivatives/sub-NDARAA117NEJ/task-RestingStateeeg/connectedscatter.html\n",
      "/Users/YujiaLiu/Desktop/test/eeg_derivatives/sub-NDARAA117NEJ/task-RestingStateeeg/sparkline.html\n",
      "/Users/YujiaLiu/Desktop/test/eeg_embedded_deriatives/agg/evheat.html\n",
      "/Users/YujiaLiu/Desktop/test/eeg_embedded_deriatives/agg/heatmap.html\n"
     ]
    }
   ],
   "source": [
    "for dirname, dirnames, filenames in os.walk('/Users/YujiaLiu/Desktop/test'):\n",
    "    for filename in filenames:\n",
    "        if not filename.endswith('DS_Store'):\n",
    "            print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/YujiaLiu/Desktop/download_test/data/eeg_derivatives/agg/squareheat.html\n",
      "/Users/YujiaLiu/Desktop/download_test/data/eeg_derivatives/agg/evheat.html\n",
      "/Users/YujiaLiu/Desktop/download_test/data/eeg_derivatives/sub-NDARAC904DMU/task-RestingStateeeg/spatialconn.html\n",
      "/Users/YujiaLiu/Desktop/download_test/data/eeg_derivatives/sub-NDARAC904DMU/task-RestingStateeeg/connectedscatter.html\n",
      "/Users/YujiaLiu/Desktop/download_test/data/eeg_derivatives/sub-NDARAC904DMU/task-RestingStateeeg/sparkline.html\n",
      "/Users/YujiaLiu/Desktop/download_test/data/eeg_derivatives/sub-NDARAA117NEJ/task-RestingStateeeg/spatialconn.html\n",
      "/Users/YujiaLiu/Desktop/download_test/data/eeg_derivatives/sub-NDARAA117NEJ/task-RestingStateeeg/connectedscatter.html\n",
      "/Users/YujiaLiu/Desktop/download_test/data/eeg_derivatives/sub-NDARAA117NEJ/task-RestingStateeeg/sparkline.html\n",
      "/Users/YujiaLiu/Desktop/download_test/data/eeg_embedded_deriatives/agg/evheat.html\n",
      "/Users/YujiaLiu/Desktop/download_test/data/eeg_embedded_deriatives/agg/heatmap.html\n"
     ]
    }
   ],
   "source": [
    "for dirname, dirnames, filenames in os.walk('/Users/YujiaLiu/Desktop/download_test/data/'):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.html'):\n",
    "            print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
